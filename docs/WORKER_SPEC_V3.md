# ğŸ”§ WEBGPT.jp v3 ãƒ¯ãƒ¼ã‚«ãƒ¼ä»•æ§˜æ›¸

ï¼ˆRedis + BullMQ ã«ã‚ˆã‚‹ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ï¼‰

## ğŸ“‹ æ¦‚è¦

v3ã§ã¯ã€å­¦ç¿’ã‚¸ãƒ§ãƒ–ã‚’**éåŒæœŸã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ **ã§å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚

ç¾åœ¨ã®å®Ÿè£…ï¼ˆ`/api/train/url`ï¼‰ã¯ã€APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå†…ã§åŒæœŸçš„ã«å‡¦ç†ã‚’é–‹å§‹ã—ã¦ã„ã¾ã™ãŒã€v3ã§ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰æ›´ã—ã¾ã™ï¼š

```
[API] â†’ [Redis Queue] â†’ [Worker] â†’ [Supabase]
```

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js    â”‚
â”‚  API Route  â”‚  POST /api/train/url
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Redis     â”‚  BullMQ Queue: "training-jobs"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 2. ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚’å–å¾—
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Worker    â”‚  Node.js ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆç‹¬ç«‹ï¼‰
â”‚  (tsx/ts-node)â”‚  - ã‚¯ãƒ­ãƒ¼ãƒ«
â”‚             â”‚  - åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
â”‚             â”‚  - Supabaseä¿å­˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 3. çµæœã‚’Supabaseã«ä¿å­˜
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Supabase   â”‚  training_jobs.statusæ›´æ–°
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

1. **APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡** (`/api/train/url`)
   - èªè¨¼ãƒã‚§ãƒƒã‚¯
   - `training_jobs` ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆï¼ˆ`status='pending'`ï¼‰
   - Redisã‚­ãƒ¥ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚’è¿½åŠ 
   - å³åº§ã« `job_id` ã‚’è¿”ã™

2. **ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†**
   - Redisã‹ã‚‰ã‚¸ãƒ§ãƒ–ã‚’å–å¾—
   - `training_jobs.status` ã‚’ `'running'` ã«æ›´æ–°
   - ã‚µã‚¤ãƒˆãƒãƒƒãƒ—/URLãƒªã‚¹ãƒˆã‹ã‚‰ãƒšãƒ¼ã‚¸ã‚’ã‚¯ãƒ­ãƒ¼ãƒ«
   - å„ãƒšãƒ¼ã‚¸ã‚’åŸ‹ã‚è¾¼ã¿åŒ–
   - `documents` ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
   - å®Œäº†æ™‚ã« `status='completed'` ã«æ›´æ–°

3. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**
   - å¤±æ•—æ™‚ã¯ `status='failed'` ã«æ›´æ–°
   - `attempt` ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
   - æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã¾ã§è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤

---

## ğŸ“¦ ä¾å­˜é–¢ä¿‚

### å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸

```json
{
  "dependencies": {
    "bullmq": "^5.0.0",
    "ioredis": "^5.3.2"
  },
  "devDependencies": {
    "@types/ioredis": "^5.0.0"
  }
}
```

### Redis ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

**ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒ**:
```bash
# Docker Compose ã‚’ä½¿ç”¨
docker run -d -p 6379:6379 redis:7-alpine
```

**æœ¬ç•ªç’°å¢ƒ**:
- Upstash Redisï¼ˆæ¨å¥¨ï¼‰
- AWS ElastiCache
- Supabase Edge Functions å†…ã§ Redis ã‚’ä½¿ç”¨

---

## ğŸ”¨ å®Ÿè£…ä»•æ§˜

### 1. ã‚­ãƒ¥ãƒ¼è¨­å®š (`lib/queue.ts`)

```typescript
import { Queue, Worker, QueueEvents } from 'bullmq';
import Redis from 'ioredis';

const connection = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD,
  maxRetriesPerRequest: null,
});

export const trainingQueue = new Queue('training-jobs', {
  connection,
  defaultJobOptions: {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000,
    },
    removeOnComplete: {
      age: 3600, // 1æ™‚é–“å¾Œã«å‰Šé™¤
      count: 1000,
    },
    removeOnFail: {
      age: 86400, // 24æ™‚é–“å¾Œã«å‰Šé™¤
    },
  },
});

export const queueEvents = new QueueEvents('training-jobs', {
  connection,
});
```

### 2. APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå¤‰æ›´ (`pages/api/train/url.ts`)

**å¤‰æ›´å‰**: åŒæœŸçš„ã«å‡¦ç†ã‚’é–‹å§‹

**å¤‰æ›´å¾Œ**: ã‚­ãƒ¥ãƒ¼ã«ã‚¸ãƒ§ãƒ–ã‚’è¿½åŠ ã—ã¦å³åº§ã«è¿”ã™

```typescript
// ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿
const jobData = {
  site_id,
  baseUrl,
  sitemapUrl,
  urlList: processedUrlList,
  userId,
  forceRetrain: req.body.force_retrain || false,
};

// ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ 
const job = await trainingQueue.add('train-site', jobData, {
  jobId: jobId, // training_jobs.id ã‚’ä½¿ç”¨
  priority: 1,
});

// å³åº§ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹
res.status(200).json({
  job_id: jobId,
  status: 'pending',
  message: 'Training job queued',
});
```

### 3. ãƒ¯ãƒ¼ã‚«ãƒ¼å®Ÿè£… (`workers/training-worker.ts`)

```typescript
import { Worker, Job } from 'bullmq';
import Redis from 'ioredis';
import { createClient } from '@supabase/supabase-js';
import { OpenAIEmbeddings } from '@langchain/openai';
// ... æ—¢å­˜ã®ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ»åŸ‹ã‚è¾¼ã¿å‡¦ç†ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

const connection = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD,
});

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const worker = new Worker(
  'training-jobs',
  async (job: Job) => {
    const { site_id, baseUrl, sitemapUrl, urlList, userId, forceRetrain } = job.data;

    try {
      // 1. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ 'running' ã«æ›´æ–°
      await supabase
        .from('training_jobs')
        .update({ 
          status: 'running',
          started_at: new Date().toISOString(),
        })
        .eq('id', job.id);

      // 2. ã‚µã‚¤ãƒˆæƒ…å ±ã‚’å–å¾—
      const { data: site } = await supabase
        .from('sites')
        .select('*')
        .eq('id', site_id)
        .single();

      if (!site) {
        throw new Error('Site not found');
      }

      // 3. ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†ï¼ˆæ—¢å­˜ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å†åˆ©ç”¨ï¼‰
      const urls = await crawlSitemap(baseUrl, sitemapUrl, urlList);
      
      // 4. å·®åˆ†æ›´æ–°ãƒã‚§ãƒƒã‚¯ï¼ˆforceRetrain=false ã®å ´åˆï¼‰
      let urlsToProcess = urls;
      if (!forceRetrain && site.last_trained_at) {
        // å‰å›å­¦ç¿’ä»¥é™ã«æ›´æ–°ã•ã‚ŒãŸURLã®ã¿å‡¦ç†
        urlsToProcess = await filterUpdatedUrls(urls, site.last_trained_at);
      }

      // 5. åŸ‹ã‚è¾¼ã¿å‡¦ç†
      const embeddings = new OpenAIEmbeddings({
        openAIApiKey: process.env.OPENAI_API_KEY!,
      });

      let processedPages = 0;
      const totalPages = urlsToProcess.length;

      for (const url of urlsToProcess) {
        // é€²æ—ã‚’æ›´æ–°
        await job.updateProgress({
          processed: processedPages,
          total: totalPages,
        });

        // ãƒšãƒ¼ã‚¸ã‚’ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ»åŸ‹ã‚è¾¼ã¿
        await processPage(url, site_id, embeddings);
        processedPages++;
      }

      // 6. å®Œäº†å‡¦ç†
      await supabase
        .from('training_jobs')
        .update({
          status: 'completed',
          finished_at: new Date().toISOString(),
          processed_pages: processedPages,
          total_pages: totalPages,
        })
        .eq('id', job.id);

      await supabase
        .from('sites')
        .update({
          status: 'ready',
          last_trained_at: new Date().toISOString(),
        })
        .eq('id', site_id);

      return { success: true, processedPages, totalPages };
    } catch (error) {
      // ã‚¨ãƒ©ãƒ¼å‡¦ç†
      await supabase
        .from('training_jobs')
        .update({
          status: 'failed',
          finished_at: new Date().toISOString(),
          error_message: error.message,
          attempt: job.attemptsMade + 1,
        })
        .eq('id', job.id);

      await supabase
        .from('sites')
        .update({ status: 'error' })
        .eq('id', site_id);

      throw error;
    }
  },
  {
    connection,
    concurrency: 3, // åŒæ™‚å®Ÿè¡Œæ•°
    limiter: {
      max: 5, // æœ€å¤§5ã‚¸ãƒ§ãƒ–/ç§’
      duration: 1000,
    },
  }
);

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
worker.on('completed', (job) => {
  console.log(`Job ${job.id} completed`);
});

worker.on('failed', (job, err) => {
  console.error(`Job ${job?.id} failed:`, err);
});

// ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
process.on('SIGTERM', async () => {
  await worker.close();
  process.exit(0);
});
```

### 4. ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (`scripts/start-worker.ts`)

```typescript
#!/usr/bin/env tsx
import 'dotenv/config';
import './workers/training-worker';

console.log('ğŸš€ Training worker started');
console.log(`Redis: ${process.env.REDIS_HOST || 'localhost'}:${process.env.REDIS_PORT || '6379'}`);
```

**package.json ã«è¿½åŠ **:
```json
{
  "scripts": {
    "worker": "tsx -r dotenv/config scripts/start-worker.ts"
  }
}
```

---

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### 1. ã‚­ãƒ¥ãƒ¼çŠ¶æ…‹ã®ç¢ºèª

```typescript
// lib/queue.ts ã«è¿½åŠ 
export async function getQueueStats() {
  const waiting = await trainingQueue.getWaitingCount();
  const active = await trainingQueue.getActiveCount();
  const completed = await trainingQueue.getCompletedCount();
  const failed = await trainingQueue.getFailedCount();

  return {
    waiting,
    active,
    completed,
    failed,
  };
}
```

### 2. ã‚¸ãƒ§ãƒ–é€²æ—ã®å–å¾—

```typescript
// API: GET /api/train/status?job_id=...
export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  const { job_id } = req.query;
  
  const job = await trainingQueue.getJob(job_id as string);
  if (!job) {
    return res.status(404).json({ message: 'Job not found' });
  }

  const state = await job.getState();
  const progress = job.progress;

  res.json({
    job_id,
    state,
    progress,
    attemptsMade: job.attemptsMade,
  });
}
```

### 3. Bull Boardï¼ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼‰

```typescript
// pages/api/admin/queue.ts
import { createBullBoard } from '@bull-board/api';
import { BullMQAdapter } from '@bull-board/api/bullMQAdapter';
import { ExpressAdapter } from '@bull-board/express';
import { trainingQueue } from '@/lib/queue';

const serverAdapter = new ExpressAdapter();
serverAdapter.setBasePath('/admin/queue');

createBullBoard({
  queues: [new BullMQAdapter(trainingQueue)],
  serverAdapter,
});

// Express ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã¨ã—ã¦ä½¿ç”¨
```

---

## ğŸ”„ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹é †

### Step 1: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
npm install bullmq ioredis
npm install -D @types/ioredis
```

### Step 2: ç’°å¢ƒå¤‰æ•°ã®è¿½åŠ 

```env
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
```

### Step 3: ã‚³ãƒ¼ãƒ‰ã®ç§»è¡Œ

1. `lib/queue.ts` ã‚’ä½œæˆ
2. `pages/api/train/url.ts` ã‚’ä¿®æ­£ï¼ˆã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ï¼‰
3. `workers/training-worker.ts` ã‚’ä½œæˆ
4. æ—¢å­˜ã®ã‚¯ãƒ­ãƒ¼ãƒ«ãƒ»åŸ‹ã‚è¾¼ã¿å‡¦ç†ã‚’ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ç§»å‹•

### Step 4: ãƒ¯ãƒ¼ã‚«ãƒ¼ã®èµ·å‹•

**é–‹ç™ºç’°å¢ƒ**:
```bash
npm run worker
```

**æœ¬ç•ªç’°å¢ƒ**:
- PM2 ã‚’ä½¿ç”¨
- Docker Compose ã§ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•
- Vercel Cron Jobsï¼ˆåˆ¶é™ã‚ã‚Šï¼‰

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤

### è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤

- **æœ€å¤§è©¦è¡Œå›æ•°**: 3å›
- **ãƒãƒƒã‚¯ã‚ªãƒ•**: æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼ˆ2ç§’ã€4ç§’ã€8ç§’ï¼‰
- **ãƒªãƒˆãƒ©ã‚¤æ¡ä»¶**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

### æ‰‹å‹•ãƒªãƒˆãƒ©ã‚¤

```typescript
// API: POST /api/train/retry?job_id=...
const job = await trainingQueue.getJob(job_id);
if (job) {
  await job.retry();
}
```

---

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ä¸¦åˆ—å‡¦ç†

- **concurrency**: 3ï¼ˆåŒæ™‚å®Ÿè¡Œã‚¸ãƒ§ãƒ–æ•°ï¼‰
- **limiter**: æœ€å¤§5ã‚¸ãƒ§ãƒ–/ç§’

### 2. ãƒãƒƒãƒå‡¦ç†

å¤§é‡ã®URLã‚’å‡¦ç†ã™ã‚‹å ´åˆã€ãƒãƒƒãƒå˜ä½ã§å‡¦ç†ï¼š

```typescript
const BATCH_SIZE = 10;
for (let i = 0; i < urls.length; i += BATCH_SIZE) {
  const batch = urls.slice(i, i + BATCH_SIZE);
  await Promise.all(batch.map(url => processPage(url)));
}
```

### 3. ãƒ¡ãƒ¢ãƒªç®¡ç†

- å®Œäº†ã—ãŸã‚¸ãƒ§ãƒ–ã¯è‡ªå‹•å‰Šé™¤ï¼ˆ1æ™‚é–“å¾Œï¼‰
- å¤±æ•—ã—ãŸã‚¸ãƒ§ãƒ–ã¯24æ™‚é–“ä¿æŒ

---

## âœ… ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] Redis ã‚µãƒ¼ãƒãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- [ ] `bullmq` ã¨ `ioredis` ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- [ ] `lib/queue.ts` ã®ä½œæˆ
- [ ] `/api/train/url` ã®ä¿®æ­£ï¼ˆã‚­ãƒ¥ãƒ¼è¿½åŠ ï¼‰
- [ ] `workers/training-worker.ts` ã®ä½œæˆ
- [ ] ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
- [ ] ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- [ ] æœ¬ç•ªç’°å¢ƒã§ã®ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•æ–¹æ³•ã®æ±ºå®š

---

## ğŸ”— å‚è€ƒãƒªãƒ³ã‚¯

- [BullMQ Documentation](https://docs.bullmq.io/)
- [Redis Documentation](https://redis.io/docs/)
- [Upstash Redis](https://upstash.com/)ï¼ˆã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹Redisï¼‰

---

ã“ã‚Œã§ **v3ãƒ¯ãƒ¼ã‚«ãƒ¼ä»•æ§˜æ›¸å®Œäº†**ã€‚

æ¬¡ã¯å®Ÿè£…ã«é€²ã‚€ã‹ã€è¿½åŠ ã®ä»•æ§˜ãŒå¿…è¦ãªã‚‰æ•™ãˆã¦ã­ï¼
